{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regresión\n",
    "\n",
    "Revisaremos los conceptos de regresión vistos en el teórico.\n",
    "\n",
    "Haremos pruebas con datos de entrada de **una dimensión**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función Verdadera Oculta\n",
    "\n",
    "Usaremos como función oculta un sinusoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sinusoidal_data(spread=0.25, data_size=50):\n",
    "    x = np.linspace(0, 1, data_size)\n",
    "    y = np.sin(2 * np.pi * x) + np.random.normal(scale=spread, size=x.shape)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, f_x = create_sinusoidal_data(0, 100)\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muestra Ruidosa\n",
    "\n",
    "Tomaremos puntos uniformes en $x$, ruidosos en $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 20\n",
    "X, y = create_sinusoidal_data(0.10, data_size)\n",
    "\n",
    "plt.scatter(X, y, color=\"blue\", label=\"datos\")\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División en Entrenamiento y Evaluación\n",
    "\n",
    "Dividiremos aleatoriamente los datos en una parte para entrenamiento y otra para evaluación.\n",
    "\n",
    "Usaremos \n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 6\n",
    "test_size = data_size - train_size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.scatter(X_test, y_test, color=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "Probaremos ajustar los puntos usando una recta.\n",
    "\n",
    "Vamos a programar a mano el aprendizaje y la predicción.\n",
    "\n",
    "### Solución de Cuadrados Mínimos\n",
    "\n",
    "Datos de entrenamiento:\n",
    "- $X \\in R^{N \\times K}:$ $N$ vectores de entrada, de $K$ dimensiones cada uno.\n",
    "- $y \\in R^N:$ $N$ valores de salida.\n",
    "\n",
    "Aprendizaje:\n",
    "\n",
    "$$w^* = (X^\\top X)^{-1} X^\\top y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_least_squares(X, y):\n",
    "    X_b = np.stack((X, np.ones(X.shape[0])), axis=1)  # add bias\n",
    "    return np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T.dot(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción:\n",
    "\n",
    "$$f_{w^*}(x) = x^\\top w^* = \\sum_{k=1}^K x_k w^*_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X, w):\n",
    "    X_b = np.stack((X, np.ones(X.shape[0])), axis=1)  # add bias\n",
    "    return X_b.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = linear_least_squares(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar\n",
    "\n",
    "Graficaremos la función aprendida a partir de los datos de entrenamiento. También graficaremos con los datos de evaluación y la función oculta, para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.scatter(X_test, y_test, color=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "plt.plot(x, f(x, w), color=\"red\", label=\"model\")\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir y Evaluar: Error Cuadrático Medio\n",
    "\n",
    "Obtendremos los valores predichos para los datos de entrenamiento y de evaluación.\n",
    "Calcularemos el error cuadrático medio sobre ambos conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = f(X_train, w)\n",
    "y_test_pred = f(X_test, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la función [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) de scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_error = mean_squared_error(y_train, y_train_pred)\n",
    "test_error = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'Train error: {train_error:0.2}')\n",
    "print(f'Test error: {test_error:0.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Polinomial\n",
    "\n",
    "Ahora haremos regresión polinomial. En este caso usaremos scikit-learn para definir el modelo, entrenar y predecir.\n",
    "\n",
    "En scikit-learn cada dato de entrada debe ser un vector, no un número. Debemos convertir cada dato en un vector de una dimensión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciar y Entrenar\n",
    "\n",
    "En scikit-learn, la regresión polinomial se implementa como un modelo de dos pasos (ver [Polynomial interpolation](https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html)).\n",
    "\n",
    "Crearemos y entrenaremos un modelo de grado 2.\n",
    "\n",
    "Como siempre en scikit-learn, para entrenar usamos la función **fit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "degree = 2\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.scatter(X_test, y_test, color=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "plt.plot(x, model.predict(x.reshape(-1, 1)), color=\"red\", label=\"model\")\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir y Evaluar\n",
    "\n",
    "Para predecir, usamos la función **predict**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = mean_squared_error(y_train, y_train_pred)\n",
    "test_error = mean_squared_error(y_test, y_test_pred)\n",
    "print(f'Train error: {train_error:0.2}')\n",
    "print(f'Test error: {test_error:0.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobreajuste vs. Generalización\n",
    "\n",
    "Probaremos polinomios de varios grados, obteniendo valores de error en entrenamiento y evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "degrees = [0, 1, 2, 3, 4, 5, 6]\n",
    "for degree in degrees:\n",
    "    # train:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict:\n",
    "    y_train_pred = model.predict(X_train.reshape(-1, 1))\n",
    "    y_test_pred = model.predict(X_test.reshape(-1, 1))\n",
    "    \n",
    "    # evaluate:\n",
    "    train_error = mean_squared_error(y_train, y_train_pred)\n",
    "    test_error = mean_squared_error(y_test, y_test_pred)\n",
    "    train_errors.append(train_error)\n",
    "    test_errors.append(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficaremos las curvas de error en términos del grado del polinomio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees, train_errors, color=\"red\", label=\"train\")\n",
    "plt.plot(degrees, test_errors, color=\"blue\", label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"degree\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el error en entrenamiento siempre baja, pero que en algún punto comienza el sobreajuste, ya que el error en evaluación empieza a subir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejor Modelo\n",
    "\n",
    "De acuerdo a la gráfica anterior, y como era de esperarse, el modelo que mejor ajusta los datos es el de grado 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.scatter(X_test, y_test, color=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "plt.plot(x, model.predict(x.reshape(-1, 1)), color=\"red\", label=\"model\")\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Sobreajustado\n",
    "\n",
    "Veamos cómo es la gráfica de uno de los modelos que sufre de sobreajuste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 6\n",
    "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"blue\", label=\"train\")\n",
    "plt.scatter(X_test, y_test, color=\"white\", edgecolor=\"k\", label=\"test\")\n",
    "plt.plot(x, model.predict(x.reshape(-1, 1)), color=\"red\", label=\"model\")\n",
    "plt.plot(x, f_x, color=\"green\", label=\"$\\sin(2\\pi x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. Probar usando regularización para prevenir el sobreajuste \n",
    "(ver [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "Scikit-learn:\n",
    "\n",
    "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)\n",
    "- [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
